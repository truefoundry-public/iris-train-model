{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "We will load data from multiple sources:\n",
    "1. Load data from External S3 bucket\n",
    "2. Load data from neo4j\n",
    "3. Load data from weaviate\n",
    "4. Load data from TrueFoundry ML Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data from External S3 bucket\n",
    "\n",
    "External S3 bucket can be accessed using IAM role attached to serviceaccount of the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T14:28:14.074257Z",
     "iopub.status.busy": "2025-06-23T14:28:14.073672Z",
     "iopub.status.idle": "2025-06-23T14:28:14.399046Z",
     "shell.execute_reply": "2025-06-23T14:28:14.398616Z",
     "shell.execute_reply.started": "2025-06-23T14:28:14.074233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/', 'dataset/dataset/dataset-A.csv', 'dataset/dataset/dataset-B.csv', 'dataset/dataset/dataset-C.csv', 'dataset/dataset/dataset-D.csv', 'dataset/dataset/dataset-E.csv', 'dataset/dataset/dataset-F.csv', 'sample.txt']\n"
     ]
    }
   ],
   "source": [
    "# !pip install boto3\n",
    "import boto3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "response = s3_client.list_objects(Bucket='tfy-usea1-ext-ctl20250623064606752500000001')\n",
    "# res = response['Body'].read().decode('utf-8')\n",
    "paths = [obj['Key'] for obj in response['Contents']]\n",
    "\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data from neo4j\n",
    "\n",
    "Connect to Neo4j instance running on TrueFoundry or any managed service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T14:28:14.399899Z",
     "iopub.status.busy": "2025-06-23T14:28:14.399592Z",
     "iopub.status.idle": "2025-06-23T14:28:14.627603Z",
     "shell.execute_reply": "2025-06-23T14:28:14.627073Z",
     "shell.execute_reply.started": "2025-06-23T14:28:14.399885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice'}\n",
      "{'name': 'Alice'}\n",
      "{'name': 'Alice'}\n",
      "The query `\n",
      "        MATCH (p:Person)-[:KNOWS]->(:Person)\n",
      "        RETURN p.name AS name\n",
      "        ` returned 3 records in 2 ms.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "URI = \"neo4j://neo4j.dev-ws.svc.cluster.local\"\n",
    "AUTH = (\"neo4j\", \"51ce8fd4-1c9a-44e8-ad3b-b9d26ea6d074\")\n",
    "\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()\n",
    "    # Create graph\n",
    "    # summary = driver.execute_query(\"\"\"\n",
    "    #     CREATE (a:Person {name: $name})\n",
    "    #     CREATE (b:Person {name: $friendName})\n",
    "    #     CREATE (a)-[:KNOWS]->(b)\n",
    "    #     \"\"\",\n",
    "    #     name=\"Alice\", friendName=\"David\",\n",
    "    #     database_=\"neo4j\",\n",
    "    # ).summary\n",
    "    # print(\"Created {nodes_created} nodes in {time} ms.\".format(\n",
    "    #     nodes_created=summary.counters.nodes_created,\n",
    "    #     time=summary.result_available_after\n",
    "    # ))\n",
    "    # Query a graph\n",
    "    records, summary, keys = driver.execute_query(\"\"\"\n",
    "        MATCH (p:Person)-[:KNOWS]->(:Person)\n",
    "        RETURN p.name AS name\n",
    "        \"\"\",\n",
    "        database_=\"neo4j\",\n",
    "    )\n",
    "    # Loop through results and do something with them\n",
    "    for record in records:\n",
    "        print(record.data())  # obtain record as dict\n",
    "    # Summary information\n",
    "    print(\"The query `{query}` returned {records_count} records in {time} ms.\".format(\n",
    "        query=summary.query, records_count=len(records),\n",
    "        time=summary.result_available_after\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load data from Weaviate\n",
    "\n",
    "Connect to Weaviate instance running on TrueFoundry or any managed service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T14:28:14.628323Z",
     "iopub.status.busy": "2025-06-23T14:28:14.628096Z",
     "iopub.status.idle": "2025-06-23T14:28:15.317246Z",
     "shell.execute_reply": "2025-06-23T14:28:15.316800Z",
     "shell.execute_reply.started": "2025-06-23T14:28:14.628309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Article': _CollectionConfigSimple(name='Article', description=None, generative_config=None, properties=[_Property(name='title', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none', vectorizer_configs=None), _Property(name='body', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none', vectorizer_configs=None)], references=[], reranker_config=None, vectorizer_config=None, vectorizer=<Vectorizers.NONE: 'none'>, vector_config=None)}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "Host = \"weaviate.dev-ws.svc.cluster.local\"\n",
    "grpcHost = \"weaviate-grpc.dev-ws.svc.cluster.local\"\n",
    "\n",
    "client = weaviate.connect_to_custom(\n",
    "    http_host=Host,\n",
    "    http_port=8080,\n",
    "    http_secure=False,\n",
    "    grpc_host=grpcHost,\n",
    "    grpc_port=50051,\n",
    "    grpc_secure=False,\n",
    ")\n",
    "# Create a new collection\n",
    "# from weaviate.classes.config import Property, DataType\n",
    "\n",
    "# # Note that you can use `client.collections.create_from_dict()` to create a collection from a v3-client-style JSON object\n",
    "# client.collections.create(\n",
    "#     \"Article\",\n",
    "#     properties=[\n",
    "#         Property(name=\"title\", data_type=DataType.TEXT),\n",
    "#         Property(name=\"body\", data_type=DataType.TEXT),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# List all collections\n",
    "resp = client.collections.list_all()\n",
    "print(resp)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load data from TrueFoundry ML Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T14:28:15.317961Z",
     "iopub.status.busy": "2025-06-23T14:28:15.317747Z",
     "iopub.status.idle": "2025-06-23T14:28:17.257321Z",
     "shell.execute_reply": "2025-06-23T14:28:17.256901Z",
     "shell.execute_reply.started": "2025-06-23T14:28:15.317946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[truefoundry.ml] 2025-06-23T14:28:16+0000 INFO Logged in to 'https://platform-admin.live-demo.truefoundry.cloud' as 'tfy-user'\n",
      "[truefoundry.ml] 2025-06-23T14:28:16+0000 INFO Downloading artifact version contents, this might take a while ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c7399fa06c492c94b6dac17e50842f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[truefoundry.ml] 2025-06-23T14:28:17+0000 INFO Downloading dataset-A.csv to /home/jovyan/train-model/dataset-A.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download dataset from ML Repo\n",
    "\n",
    "from truefoundry.ml import get_client\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"truefoundry\")\n",
    "client = get_client()\n",
    "\n",
    "# Log Artifact\n",
    "# artifact_version = client.log_artifact(\n",
    "#     ml_repo=\"bank-customer-churn\",\n",
    "#     name=\"locally-uploaded\",\n",
    "#     artifact_paths=[\n",
    "#         # Add all your files or folders here\n",
    "#         # The second element in the tuple is the destination path in the artifact relative to the root\n",
    "#         (\"./dataset-A.csv\", None),\n",
    "#     ],\n",
    "# )\n",
    "# print(f\"Artifact version {artifact_version.fqn} created successfully\")\n",
    "\n",
    "\n",
    "# Get the artifact version directly\n",
    "artifact_version = client.get_artifact_version_by_fqn(\"artifact:live-demo/bank-customer-churn/locally-uploaded:3\")\n",
    "\n",
    "# download it to disk\n",
    "# `download_path` points to a directory that has all contents of the artifact\n",
    "download_path = artifact_version.download(path=\".\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgTqSS3Q7J46"
   },
   "source": [
    "# Step 1: Implement the training code\n",
    "\n",
    "The first step is to create a job that trains a scikit learn model on iris dataset\n",
    "\n",
    "We start with a `train.py` containing our training code and `requirements.txt` with our dependencies.\n",
    "\n",
    "```\n",
    ".\n",
    "├── train.py\n",
    "└── requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewNT1fG07tRY"
   },
   "source": [
    "### **`train.py`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-23T14:28:17.258362Z",
     "iopub.status.busy": "2025-06-23T14:28:17.258050Z",
     "iopub.status.idle": "2025-06-23T14:28:17.262298Z",
     "shell.execute_reply": "2025-06-23T14:28:17.261723Z",
     "shell.execute_reply.started": "2025-06-23T14:28:17.258347Z"
    },
    "id": "LuU9kOzv7Ci7",
    "outputId": "002753bd-6b23-48ff-aff6-9fa5c0f380d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "X = X.rename(columns={\n",
    "        \"sepal length (cm)\": \"sepal_length\",\n",
    "        \"sepal width (cm)\": \"sepal_width\",\n",
    "        \"petal length (cm)\": \"petal_length\",\n",
    "        \"petal width (cm)\": \"petal_width\",\n",
    "})\n",
    "\n",
    "# NOTE:- You can pass these configurations via command line\n",
    "# arguments, config file, environment variables.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_true=y_test, y_pred=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exa3CI-T7jnR"
   },
   "source": [
    "Click on this [link](https://docs.truefoundry.com/v0.1.1/recipes/training-a-scikit-learn-model) to understand the **`app.py`**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1zqWidl7yTS"
   },
   "source": [
    "### **`requirements.txt`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-23T14:28:17.264101Z",
     "iopub.status.busy": "2025-06-23T14:28:17.263907Z",
     "iopub.status.idle": "2025-06-23T14:28:17.270054Z",
     "shell.execute_reply": "2025-06-23T14:28:17.269687Z",
     "shell.execute_reply.started": "2025-06-23T14:28:17.264082Z"
    },
    "id": "vHJts2tR7bfw",
    "outputId": "7b4c8cbb-2e42-4e6c-e265-d7acf59ffc6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas==1.5.3\n",
    "numpy==1.23.2\n",
    "scikit-learn==1.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtwCrPGJ750K"
   },
   "source": [
    "# Step 2: Deploying as a Job\n",
    "\n",
    "You can deploy services on TrueFoundry programmatically via our **Python SDK**.\n",
    "\n",
    "Create the `deploy.py`, after which our file structure will look like this:\n",
    "\n",
    "**File Structure**\n",
    "\n",
    "```Text\n",
    ".\n",
    "├── train.py\n",
    "├── deploy.py\n",
    "└── requirements.txt\n",
    "```\n",
    "\n",
    "### **`deploy.py`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-23T14:28:17.270567Z",
     "iopub.status.busy": "2025-06-23T14:28:17.270436Z",
     "iopub.status.idle": "2025-06-23T14:28:17.275797Z",
     "shell.execute_reply": "2025-06-23T14:28:17.275326Z",
     "shell.execute_reply.started": "2025-06-23T14:28:17.270555Z"
    },
    "id": "jc-yRSkE7xdD",
    "outputId": "ffa6fcc8-f43d-4238-8138-ed5131b2322c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy.py\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "from truefoundry.deploy import Build, Job, PythonBuild, LocalSource\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(name)s] %(levelname)-8s %(message)s\"\n",
    ")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--workspace_fqn\", required=True, type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "job = Job(\n",
    "    name=\"iris-train-job\",\n",
    "    image=Build(\n",
    "        build_source=LocalSource(local_build=False),\n",
    "        build_spec=PythonBuild(\n",
    "            python_version=\"3.11\",\n",
    "            command=\"python train.py\",\n",
    "            requirements_path=\"requirements.txt\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "job.deploy(workspace_fqn=args.workspace_fqn, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bjVtz5v829H"
   },
   "source": [
    "Now to deploy our Job run the command below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-23T14:28:17.276423Z",
     "iopub.status.busy": "2025-06-23T14:28:17.276273Z",
     "iopub.status.idle": "2025-06-23T14:28:19.221570Z",
     "shell.execute_reply": "2025-06-23T14:28:19.221033Z",
     "shell.execute_reply.started": "2025-06-23T14:28:17.276409Z"
    },
    "id": "OBNeK70h85L1",
    "outputId": "58c98c1d-9622-46b3-e977-8eb9e195d22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: deploy.py [-h] --workspace_fqn WORKSPACE_FQN\n",
      "deploy.py: error: argument --workspace_fqn: expected one argument\n"
     ]
    }
   ],
   "source": [
    "!python deploy.py --workspace_fqn \"tfy-aws:dev-ws\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".conda-jupyter-base",
   "language": "python",
   "name": "conda-env-.conda-jupyter-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
