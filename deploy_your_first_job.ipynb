{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "We will load data from multiple sources:\n",
    "1. Load data from External S3 bucket\n",
    "2. Load data from neo4j\n",
    "3. Load data from weaviate\n",
    "4. Load data from TrueFoundry ML Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data from External S3 bucket\n",
    "\n",
    "External S3 bucket can be accessed using IAM role attached to serviceaccount of the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T14:55:23.770952Z",
     "iopub.status.busy": "2025-06-23T14:55:23.770548Z",
     "iopub.status.idle": "2025-06-23T14:55:23.843976Z",
     "shell.execute_reply": "2025-06-23T14:55:23.843423Z",
     "shell.execute_reply.started": "2025-06-23T14:55:23.770932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset/', 'dataset/dataset/dataset-A.csv', 'dataset/dataset/dataset-B.csv', 'dataset/dataset/dataset-C.csv', 'dataset/dataset/dataset-D.csv', 'dataset/dataset/dataset-E.csv', 'dataset/dataset/dataset-F.csv', 'sample.txt']\n"
     ]
    }
   ],
   "source": [
    "# !pip install boto3\n",
    "import boto3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "response = s3_client.list_objects(Bucket='tfy-usea1-ext-ctl20250623064606752500000001')\n",
    "# res = response['Body'].read().decode('utf-8')\n",
    "paths = [obj['Key'] for obj in response['Contents']]\n",
    "\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data from neo4j\n",
    "\n",
    "Connect to Neo4j instance running on TrueFoundry or any managed service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T14:55:26.832883Z",
     "iopub.status.busy": "2025-06-23T14:55:26.832430Z",
     "iopub.status.idle": "2025-06-23T14:55:26.881501Z",
     "shell.execute_reply": "2025-06-23T14:55:26.880915Z",
     "shell.execute_reply.started": "2025-06-23T14:55:26.832862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice'}\n",
      "{'name': 'Alice'}\n",
      "{'name': 'Alice'}\n",
      "The query `\n",
      "        MATCH (p:Person)-[:KNOWS]->(:Person)\n",
      "        RETURN p.name AS name\n",
      "        ` returned 3 records in 2 ms.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "URI = \"neo4j://neo4j.dev-ws.svc.cluster.local\"\n",
    "AUTH = (\"neo4j\", \"51ce8fd4-1c9a-44e8-ad3b-b9d26ea6d074\")\n",
    "\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()\n",
    "    # Create graph\n",
    "    # summary = driver.execute_query(\"\"\"\n",
    "    #     CREATE (a:Person {name: $name})\n",
    "    #     CREATE (b:Person {name: $friendName})\n",
    "    #     CREATE (a)-[:KNOWS]->(b)\n",
    "    #     \"\"\",\n",
    "    #     name=\"Alice\", friendName=\"David\",\n",
    "    #     database_=\"neo4j\",\n",
    "    # ).summary\n",
    "    # print(\"Created {nodes_created} nodes in {time} ms.\".format(\n",
    "    #     nodes_created=summary.counters.nodes_created,\n",
    "    #     time=summary.result_available_after\n",
    "    # ))\n",
    "    # Query a graph\n",
    "    records, summary, keys = driver.execute_query(\"\"\"\n",
    "        MATCH (p:Person)-[:KNOWS]->(:Person)\n",
    "        RETURN p.name AS name\n",
    "        \"\"\",\n",
    "        database_=\"neo4j\",\n",
    "    )\n",
    "    # Loop through results and do something with them\n",
    "    for record in records:\n",
    "        print(record.data())  # obtain record as dict\n",
    "    # Summary information\n",
    "    print(\"The query `{query}` returned {records_count} records in {time} ms.\".format(\n",
    "        query=summary.query, records_count=len(records),\n",
    "        time=summary.result_available_after\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load data from Weaviate\n",
    "\n",
    "Connect to Weaviate instance running on TrueFoundry or any managed service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T14:55:28.832566Z",
     "iopub.status.busy": "2025-06-23T14:55:28.832143Z",
     "iopub.status.idle": "2025-06-23T14:55:28.911268Z",
     "shell.execute_reply": "2025-06-23T14:55:28.910742Z",
     "shell.execute_reply.started": "2025-06-23T14:55:28.832549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Article': _CollectionConfigSimple(name='Article', description=None, generative_config=None, properties=[_Property(name='title', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none', vectorizer_configs=None), _Property(name='body', description=None, data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=None, vectorizer='none', vectorizer_configs=None)], references=[], reranker_config=None, vectorizer_config=None, vectorizer=<Vectorizers.NONE: 'none'>, vector_config=None)}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "Host = \"weaviate.dev-ws.svc.cluster.local\"\n",
    "grpcHost = \"weaviate-grpc.dev-ws.svc.cluster.local\"\n",
    "\n",
    "client = weaviate.connect_to_custom(\n",
    "    http_host=Host,\n",
    "    http_port=8080,\n",
    "    http_secure=False,\n",
    "    grpc_host=grpcHost,\n",
    "    grpc_port=50051,\n",
    "    grpc_secure=False,\n",
    ")\n",
    "# Create a new collection\n",
    "# from weaviate.classes.config import Property, DataType\n",
    "\n",
    "# # Note that you can use `client.collections.create_from_dict()` to create a collection from a v3-client-style JSON object\n",
    "# client.collections.create(\n",
    "#     \"Article\",\n",
    "#     properties=[\n",
    "#         Property(name=\"title\", data_type=DataType.TEXT),\n",
    "#         Property(name=\"body\", data_type=DataType.TEXT),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# List all collections\n",
    "resp = client.collections.list_all()\n",
    "print(resp)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load data from TrueFoundry ML Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T14:55:31.249265Z",
     "iopub.status.busy": "2025-06-23T14:55:31.248808Z",
     "iopub.status.idle": "2025-06-23T14:55:31.619240Z",
     "shell.execute_reply": "2025-06-23T14:55:31.618769Z",
     "shell.execute_reply.started": "2025-06-23T14:55:31.249246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[truefoundry.ml] 2025-06-23T14:55:31+0000 INFO Downloading artifact version contents, this might take a while ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424fe90b664b4bf38f0aca106745ebdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[truefoundry.ml] 2025-06-23T14:55:31+0000 INFO Downloading dataset-A.csv to /home/jovyan/train-model/dataset-A.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download dataset from ML Repo\n",
    "\n",
    "from truefoundry.ml import get_client\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"truefoundry\")\n",
    "client = get_client()\n",
    "\n",
    "# Log Artifact\n",
    "# artifact_version = client.log_artifact(\n",
    "#     ml_repo=\"bank-customer-churn\",\n",
    "#     name=\"locally-uploaded\",\n",
    "#     artifact_paths=[\n",
    "#         # Add all your files or folders here\n",
    "#         # The second element in the tuple is the destination path in the artifact relative to the root\n",
    "#         (\"./dataset-A.csv\", None),\n",
    "#     ],\n",
    "# )\n",
    "# print(f\"Artifact version {artifact_version.fqn} created successfully\")\n",
    "\n",
    "\n",
    "# Get the artifact version directly\n",
    "artifact_version = client.get_artifact_version_by_fqn(\"artifact:live-demo/bank-customer-churn/locally-uploaded:3\")\n",
    "\n",
    "# download it to disk\n",
    "# `download_path` points to a directory that has all contents of the artifact\n",
    "download_path = artifact_version.download(path=\".\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgTqSS3Q7J46"
   },
   "source": [
    "# Step 1: Implement the training code\n",
    "\n",
    "The first step is to create a job that trains a scikit learn model on iris dataset\n",
    "\n",
    "We start with a `train.py` containing our training code and `requirements.txt` with our dependencies.\n",
    "\n",
    "```\n",
    ".\n",
    "├── train.py\n",
    "└── requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewNT1fG07tRY"
   },
   "source": [
    "### **`train.py`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-23T14:55:08.026770Z",
     "iopub.status.busy": "2025-06-23T14:55:08.026466Z",
     "iopub.status.idle": "2025-06-23T14:55:08.030748Z",
     "shell.execute_reply": "2025-06-23T14:55:08.030296Z",
     "shell.execute_reply.started": "2025-06-23T14:55:08.026756Z"
    },
    "id": "LuU9kOzv7Ci7",
    "outputId": "002753bd-6b23-48ff-aff6-9fa5c0f380d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "X = X.rename(columns={\n",
    "        \"sepal length (cm)\": \"sepal_length\",\n",
    "        \"sepal width (cm)\": \"sepal_width\",\n",
    "        \"petal length (cm)\": \"petal_length\",\n",
    "        \"petal width (cm)\": \"petal_width\",\n",
    "})\n",
    "\n",
    "# NOTE:- You can pass these configurations via command line\n",
    "# arguments, config file, environment variables.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_true=y_test, y_pred=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Exa3CI-T7jnR"
   },
   "source": [
    "Click on this [link](https://docs.truefoundry.com/v0.1.1/recipes/training-a-scikit-learn-model) to understand the **`app.py`**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1zqWidl7yTS"
   },
   "source": [
    "### **`requirements.txt`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-23T14:55:08.032328Z",
     "iopub.status.busy": "2025-06-23T14:55:08.032128Z",
     "iopub.status.idle": "2025-06-23T14:55:08.036383Z",
     "shell.execute_reply": "2025-06-23T14:55:08.035913Z",
     "shell.execute_reply.started": "2025-06-23T14:55:08.032310Z"
    },
    "id": "vHJts2tR7bfw",
    "outputId": "7b4c8cbb-2e42-4e6c-e265-d7acf59ffc6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas==1.5.3\n",
    "numpy==1.23.2\n",
    "scikit-learn==1.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtwCrPGJ750K"
   },
   "source": [
    "# Step 2: Deploying as a Job\n",
    "\n",
    "You can deploy services on TrueFoundry programmatically via our **Python SDK**.\n",
    "\n",
    "Create the `deploy.py`, after which our file structure will look like this:\n",
    "\n",
    "**File Structure**\n",
    "\n",
    "```Text\n",
    ".\n",
    "├── train.py\n",
    "├── deploy.py\n",
    "└── requirements.txt\n",
    "```\n",
    "\n",
    "### **`deploy.py`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-23T14:55:08.037003Z",
     "iopub.status.busy": "2025-06-23T14:55:08.036831Z",
     "iopub.status.idle": "2025-06-23T14:55:08.042200Z",
     "shell.execute_reply": "2025-06-23T14:55:08.041758Z",
     "shell.execute_reply.started": "2025-06-23T14:55:08.036990Z"
    },
    "id": "jc-yRSkE7xdD",
    "outputId": "ffa6fcc8-f43d-4238-8138-ed5131b2322c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy.py\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from truefoundry.deploy import Build, Job, PythonBuild, LocalSource\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s [%(name)s] %(levelname)-8s %(message)s\"\n",
    ")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--workspace_fqn\", required=True, type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "job = Job(\n",
    "    name=\"iris-train-job\",\n",
    "    image=Build(\n",
    "        build_source=LocalSource(local_build=False),\n",
    "        build_spec=PythonBuild(\n",
    "            python_version=\"3.11\",\n",
    "            command=\"python train.py\",\n",
    "            requirements_path=\"requirements.txt\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "job.deploy(workspace_fqn=args.workspace_fqn, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bjVtz5v829H"
   },
   "source": [
    "Now to deploy our Job run the command below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-23T14:55:08.042914Z",
     "iopub.status.busy": "2025-06-23T14:55:08.042707Z",
     "iopub.status.idle": "2025-06-23T14:55:10.860815Z",
     "shell.execute_reply": "2025-06-23T14:55:10.860200Z",
     "shell.execute_reply.started": "2025-06-23T14:55:08.042894Z"
    },
    "id": "OBNeK70h85L1",
    "outputId": "58c98c1d-9622-46b3-e977-8eb9e195d22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-23 14:55:09,675 [truefoundry] INFO     Logged in to 'https://platform-admin.live-demo.truefoundry.cloud' as 'tfy-user'\n",
      "2025-06-23 14:55:09,721 [truefoundry] INFO     Image will be built remotely because `image.build_source.local_build` is set to `false`. For faster builds it is recommended to install Docker locally and set `image.build_source.local_build` to `true` in your YAML spec or equivalently set `image=Build(build_source=LocalSource(local_build=True, ...))` in your `Service` or `Job` definition code.\n",
      "2025-06-23 14:55:09,721 [truefoundry] INFO     Uploading code for job 'iris-train-job'\n",
      "2025-06-23 14:55:09,723 [truefoundry] INFO     Archiving contents of dir: '/home/jovyan/train-model'\n",
      "2025-06-23 14:55:09,753 [truefoundry] INFO     Git repository detected in source. Files added in .gitignore will be ignored.\n",
      "If you don't want to ignore these files or otherwise, please create .tfyignore file and add file patterns to ignore.\n",
      "Packaging source code: 37it [00:00, 173.66it/s]\n",
      "2025-06-23 14:55:09,967 [truefoundry] INFO     Code archive size: '64.92 KiB'\n",
      "Uploading package: 100%|████████████████████| 64.9k/64.9k [00:00<00:00, 663kB/s]\n",
      "2025-06-23 14:55:10,460 [truefoundry] INFO     🚀 Deployment started for application 'iris-train-job'. Deployment FQN is 'tfy-aws:dev-ws:iris-train-job:2'.\n",
      "2025-06-23 14:55:10,461 [truefoundry] INFO     Deployment FQN: tfy-aws:dev-ws:iris-train-job:2\n",
      "2025-06-23 14:55:10,461 [truefoundry] INFO     Application FQN: tfy-aws:dev-ws:iris-train-job\n",
      "2025-06-23 14:55:10,462 [truefoundry] INFO     You can find the application on the dashboard:- 'https://platform-admin.live-demo.truefoundry.cloud/applications/cmc959lsy09i201nbdnje9ihv?tab=deployments'\n"
     ]
    }
   ],
   "source": [
    "!python deploy.py --workspace_fqn \"tfy-aws:dev-ws\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".conda-jupyter-base",
   "language": "python",
   "name": "conda-env-.conda-jupyter-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
